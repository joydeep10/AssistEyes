# AssistEyes

Visual Assistance for the Impaired
This project aims to empower visually impaired individuals by providing real-time, context-aware assistance using image analysis. By leveraging modern AI technologies, this application provides detailed scene descriptions, text extraction, object detection, and personalized task-specific guidance to help users navigate their environments with ease. The system also supports language translation and audio output, ensuring accessibility across different languages and enhancing the user experience.

Key Features
Scene Description
Describes the content of the uploaded image using AI models, detailing the objects, colors, and spatial relationships present in the scene.
This functionality helps visually impaired users understand complex visual environments.
OCR (Text Extraction)
Extracts any text found in images, such as product labels, documents, and signs, and reads it aloud for accessibility.
Object Detection
Detects and labels objects in the image with bounding boxes and confidence scores. Provides context-aware guidance based on detected objects.
Personalized Assistance
Provides task-specific guidance based on the content of the uploaded image, such as identifying groceries, reading labels, or providing contextual assistance in specific environments like a kitchen or office.
Text Translation
Detects text in images and translates it into the user's preferred language, making multi-lingual text accessible.
Audio Translation
After translating the text, the system reads the translated text aloud in the selected language, ensuring multi-language accessibility for visually impaired users.
